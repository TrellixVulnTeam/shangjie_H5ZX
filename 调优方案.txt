NLP数据模型训练样本处理：

    近义词替换（关键词 textrank）（word2vec或fasttext词向量）

    MASK相关词（随机替换，实现模型预测训练泛化）

模型自身：

    寻找更SOTA损失函数 focus loss，smoothlabel loss，smoothlabel
    余弦退火 learn rate(lr) 先上升后缓步下降

融合模型：

    stacking模式：

        分层训练： 数据集拆分成，训练和测试集
                  准备第1层模型，都可以完成任务(分类、NER、分词)
                  训练集K-fold拆分成K分，对第一层每个模型训练K次
                  (其中K-1份训练集，1份验证集)，生成预测结果拼接成新“训练集”

                  假设第1层有3个模型，通过训练和预测，得到3*训练集大小的新“训练集”
                  第1层每个模型，都会用相同测试集，重复K次预测。预测结果均值

                  第2层放置真正预测模型，使用第1层新“训练集”，进行训练并预测


开箱即用NLP模块：

    fasttext —— 文本分类
    spacy —— 基于流水线成熟NLP工具（分词、词性、ner）
    kashgari —— 基于Keras4bert模型，分词、分类、ner


